\documentclass[12pt,a4paper]{article}
\usepackage[american]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[utf8x]{inputenc}
\setlength{\parindent}{1.5em}
\setlength{\parskip}{0.5em}
\usepackage{indentfirst}
\usepackage{float}
\usepackage{systeme}
\usepackage[bitstream-charter]{mathdesign}
\usepackage[T1]{fontenc}
% \usepackage[frenchmath]{newtxmath}
\usepackage[frenchmath]{mathastext}
% \renewcommand*\oldstylenums[1]{{\firaoldstyle #1}}
\usepackage[titles]{tocloft}
\renewcommand{\cftdot}{}
\usepackage[colorlinks=true, allcolors=magenta, backref=page]{hyperref}
\usepackage{url}
\usepackage{graphicx}
%\usepackage{sectsty}
%\allsectionsfont{\mdseries\scshape}

% Colors
\usepackage[dvipsnames]{xcolor}
\definecolor{fireopal}{rgb}{0.93, 0.38, 0.33}
\definecolor{aquamarine}{rgb}{0.38, 0.83, 0.58}
\definecolor{mintgreen}{rgb}{0.67, 0.97, 0.51}
\definecolor{crayola}{rgb}{1, 0.85, 0.49}
\definecolor{tangerine}{rgb}{1, 0.61, 0.52}

\usepackage{amsthm}
\newtheoremstyle{break}%
{}{}%
{\itshape}{}%
{\bfseries}{}% % Note that final punctuation is omitted.
{\newline}{}
%\theoremstyle{break}
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{example}{Example}[section]
\newtheorem{definition}{Definition}[section]
\renewcommand\qedsymbol{$\blacksquare$}

% TColorBox
%\usepackage{tcolorbox}
%\tcbuselibrary{theorems,breakable}
%\tcbsetforeverylayer{autoparskip, breakable}
%\newtcbtheorem[number within=section]{thm}{Theorem}%
%{colback=white!5,colframe=fireopal!35!black,fonttitle=\bfseries, arc=0mm}{theorem}
%\newtcbtheorem[number within=section]{corollary}{Corollary}%
%{colback=white!5,colframe=aquamarine!35!black,fonttitle=\bfseries, arc=0mm}{theorem}
%\newtcbtheorem[number within=section]{example}{Example}%
%{colback=white!5,colframe=tangerine!35!black,fonttitle=\bfseries, arc=0mm}{theorem}
%\newtcbtheorem[number within=section]{defn}{Definition}%
%{colback=white!5,colframe=mintgreen!35!black,fonttitle=\bfseries, arc=0mm}{theorem}

% NEW COMMANDS
\newcommand\restr[2]{{% we make the whole thing an ordinary symbol
  \left.\kern-\nulldelimiterspace % automatically resize the bar with \right
  #1 % the function
  \vphantom{\big|} % pretend it's a little taller at normal size
  \right|_{#2} % this is the delimiter
  }}
  
%\usepackage{sectsty}
%\subsectionfont{\color{RubineRed}}
\hypersetup{
    colorlinks=true,
    linkcolor=fireopal,
    filecolor=aquamarine,      
    urlcolor=fireopal,
    pdftitle={An Introduction to Stochastic Differential Equations},
    pdfpagemode=FitH,
}
\author{\href{https://github.com/adairneto}{Adair Antonio da Silva Neto}}
\title{An Introduction to Stochastic Differential Equations}

\begin{document}

\clearpage\maketitle
\thispagestyle{empty}

\newpage

\tableofcontents

\newpage
\clearpage
\setcounter{page}{1}

\section{Introduction}

Present the kind of problems we're going to work on, and sketch the way.

\newpage
\section{Mathematical Preliminaries}

\subsection{Probability Spaces}

A probability space starts with a set $\Omega$ called the \textbf{sample space}, which is, intuitively, a list of all possible outcomes of an experiment. Each $\omega \in \Omega$ is a \textbf{sample point}, and each subset $A \subseteq \Omega$ is an \textbf{event}.

To filter `well-behaved' subsets, where it will be possible to measure a probability, the following definition is necessary.

\begin{definition}[$\sigma$-algebra]
	If $\Omega$ is a set, then a \textbf{$\sigma$-algebra} $\mathfrak{F}$ on $\Omega$ is a family of subsets of $\Omega$ satisfying:
	\begin{enumerate}
		\item $\emptyset \in \mathfrak{F}$.
		\item If $A \in \mathfrak{F}$, then $A^c \in \mathfrak{F}$.
		\item If $A_1, A_2, \ldots \in \mathfrak{F}$, then $\bigcup_{i=1}^\infty A_i \in \mathfrak{F}$.
	\end{enumerate}
	The pair $(\Omega, \mathfrak{F})$ is said to be a \textbf{measurable space}, and any subset $B \subseteq \Omega$ that also belongs to $\mathfrak{F}$ is called a \textbf{measurable set}.
\end{definition}

\begin{example}[Examples of $\sigma$-algebras]
	The following are $\sigma$-algebras.
	\begin{enumerate}
		\item The family $\{\emptyset, \Omega\}$ is called the \textbf{trivial $\sigma$-algebra}, and is the smallest one possible.
		\item The power set $\mathfrak{P}(\Omega)$ is called the \textbf{discrete $\sigma$-algebra}, and is the largest one possible.
		\item The family $\{\emptyset, \Omega, A, A^c\}$ is the \textbf{$\sigma$-algebra generated by the set $A$} and is usually denoted by $\mathfrak{F}_A$.
	\end{enumerate}
\end{example}

But the most important $\sigma$-algebra for probability theory is the Borel $\sigma$-algebra, which will be denoted by $\mathfrak{B}$. Taking $\Omega = \mathbb{R}$, the Borel $\sigma$-algebra is generated by the intersection of all $\sigma$-algebras containing the real line intervals.

Notice that the Borel $\sigma$-algebra contains all open sets, closed sets, and all their countable operations with union $\cup$, intersection $\cap$, and their complements $^c$. This is the smallest $\sigma$-algebra containing all open subsets.

More generally, if $U$ is the collection of all open subsets of a topological space $\Omega$, then $\mathfrak{B}$ is called the \textbf{Borel $\sigma$-algebra} on $\Omega$. The elements $B \in \mathfrak{B}$ are called \textbf{Borel sets}.

Given a measurable space, it's possible to assign each outcome to a probability.

\begin{definition}[Probability Measure]
	Let $(\Omega, \mathfrak{F})$ be a measurable space. A \textbf{probability measure} $P$ is the function
	\[
		P : \mathfrak{F} \longrightarrow [0,1]
	\]
	satisfying
	\begin{enumerate}
		\item $P(\emptyset) = 0$ and $P(\Omega) = 1$.
		\item ($\sigma$-additivity). If $A_1, A_2, \ldots \in \mathfrak{F}$ and $A_i \cap A_j = \emptyset$, for $i \neq j$ (i.e. are mutually exclusive), then \[ P \left( \bigcup_{i=1}^\infty A_i \right) = \sum_{i=1}^\infty P(A_i)\]
	\end{enumerate}
	
	And the triple $(\Omega, \mathfrak{F}, P)$ is called a \textbf{probability space}.
\end{definition}

In order to restrict the functions to sets in the $\sigma$-algebra, the following definition will be needed.

\begin{definition}[$\mathfrak{F}$-measurable function]
	Given a probability space $(\Omega, \mathfrak{F}, P)$, a function $Y$ from the sample space $\Omega$ to $\textbf{R}^n$ is called $\mathfrak{F}$-measurable if
	\[
		Y^{-1}(U) = \{ \omega \in \Omega : Y(\omega) \in U\} \in \mathfrak{F}
	\]
	for all open sets $U \in \textbf{R}^n$ (i.e. for all Borel sets $U \subseteq \textbf{R}^n$). In other words, the inverse image of $U$ is in the $\sigma$-algebra.
\end{definition} 

And to attach numerical values to each $\omega \in \Omega$, define the following function.

% Define complete probability space

\begin{definition}[Random variable]
	An $\mathfrak{F}$-measurable function $X: \Omega \longrightarrow \textbf{R}^n$ is called a \textbf{random variable} on a complete probability space $(\Omega, \mathfrak{F}, P)$. 
\end{definition}

This definition means that if we know which event $U$ in the $\mathfrak{F}$ has occurred, then we know which value of $X$ has occurred. 

Consider the measurable space $(\Omega, \mathfrak{P}(\Omega))$, and let $X$ be a random variable with values $x_i$, $i = 1,2, \ldots, k$. The sets
\[
	A_i = \{ \omega \in \Omega : X(\omega) = x_i \} \subseteq \Omega
\]
form a partition of $\Omega$, and the $\sigma$-algebra generated by this partition is called the \textbf{$\sigma$-algebra generated by $X$}.

Notice that this is the smallest $\sigma$-algebra that contains all the sets $A_i$. This $\sigma$-algebra is often denoted by $\mathfrak{F}_X$. Intuitively, this $\sigma$-algebra represents all information available about the sample point $\omega$ by observing $X$. 

% A random variable induces a probability measure. 

\subsection{Distribution and Density of a Random Variable}

However, given only the probability measure $P$, it is not always immediate how to compute the probability of a given interval, set or value. For that purpose, the following three definitions will be useful.

\begin{definition}[Distribution]
	The \textbf{distribution} of a random variable $X$ is a function $\mu_X : \Omega \longrightarrow \textbf{R}^n$ defined as
	\[
		\mu_X(B) = P [X^{-1}(B)] = P[X \in B] = P(\{ \omega : X(\omega) \in B \})
	\]
\end{definition}

\begin{definition}[Distribution Function]
	The \textbf{cumulative distribution function} (CDF) of a random variable $X$ is defined as
	\[
		F_X(x) = P [X \leq x] = P(\{ \omega : X(\omega) \leq x \})
	\]
	where $x \in \textbf{R}$. Notice that $F$ is non-decreasing, and right-continuous, and approaches $0$ at $- \infty$ and $1$ at $+\infty$.
\end{definition}

\begin{definition}[Joint Distribution]
	If $X$ and $Y$ are random variables, then their \textbf{joint distribution function} is
	\[
		F_{X,Y}(x,y) = P [X \leq x, Y \leq y]
	\]
	where $x,y \in \textbf{R}$.
\end{definition}

The distribution function gives the probability that the random variable $X$ is on the interval $(-\infty, x]$. This also allows to look for an interval $[a,b]$ using $F_X(b) - F_X(a)$.

While the distribution of $X$ returns the probability of an event $\{ \omega : X(\omega) \in B\}$.

\begin{definition}[Density function]
	A random variable $X$ has a \textbf{probability density function} (PDF) $f : \textbf{R}^n \longrightarrow \textbf{R}$ if $f$ is a measurable function and \[ F_X(x) = P[X \leq x] = \int_{-\infty}^x f(y) \mathrm{d}y \]
\end{definition}

\subsection{Expected Value and Variance}

Another useful tool for any given random variable is to know its mean value and how much it varies. This motivates the following.

\begin{definition}[Expectation]
	Let $(\Omega, \mathfrak{F}, P)$ be a probability space and $X$ a random variable. If $\int_{\Omega} |X(\omega)|\mathrm{d}P(\omega) < \infty$, then the \textbf{expected value} (or \textbf{mean value} of $X$ with respect to $P$ is
	\[
		\mathbb{E}[X] = \int_{\Omega} X(\omega) \mathrm{d}P(\omega) = \int_{\textbf{R}^n} x \mathrm{d}\mu_X(x)
	\]
\end{definition}

Notice that the expectation is linear. I.e., if $X$ and $Y$ are integrable and $a$ and $b$ are constants, then \[ \mathbb{E} [aX+bY] = a \mathbb{E}[X] + b \mathbb{E}[Y] \]

If $f$ is a Borel measurable function and $\int_{\Omega} |f(X)| \mathrm{d} P(\omega) < \infty$, then
\[
	\mathbb{E}[f(X)] = \int_{\Omega} f(X(\omega)) \mathrm{d} P(\omega) = \int_{\textbf{R}^n} f(X) \mathrm{d}\mu_X(x)
\]

\begin{theorem}[Chebychev's inequality]
	\[
		P[ |X| \geq \lambda] \leq \frac{1}{\lambda^p} \mathbb{E}[|X|^p]
	\]
	for all $\lambda \geq 0$.
\end{theorem}

\begin{definition}[Variance]
	Let $\mu := \mathbb{E}[X]$, i.e., the expected value of a random variable $X$. Then the \textbf{variance} of $X$ is given by
	\[
		\text{Var}[X] = \mathbb{E}[\|X - \mu\|^2] = \int_{\Omega} |X - \mu|^2 \mathrm{d} P(\omega)
	\]
\end{definition}

\begin{definition}[Covariance]
	Let $X$ and $Y$ be integral random variables. Let $\mu_X = \mathbb{E}[X]$ and $\mu_Y = \mathbb{E}[Y]$. If $XY$ is integrable, then the \textbf{covariance} of $X$ and $Y$ is:
	\[
		\text{Cov}[X,Y] = \mathbb{E}[(X-\mu_X)(Y-\mu_Y)] = \mathbb{E}[XY]-\mu_X \mu_Y
	\]
	Notice that $\text{Var}[X] = \text{Cov}[X,X]$.
\end{definition}

The variance of $X$ can be computed more simply using the following theorem.

\begin{theorem}
	Let $X$ be a random variable. Then,
	\begin{enumerate}
		\item $\text{Var}[X] = \mathbb{E}[X^2] - \mathbb{E}[X]^2$.
		\item $\text{Var}[aX+b] = a^2 \text{Var}[X]$.
		\item $\text{Cov}[X,Y] = \text{Cov}[Y,X]$.
		\item $\text{Cov}[aX+bY,Z] = a \text{Cov}[X,Z] + b \text{Cov}[Y,Z]$.
		\item $\text{Var}[X+Y] = \text{Var}[X] + \text{Var}[Y] + 2 \text{Cov}[X,Y]$.
	\end{enumerate}		
\end{theorem}

\begin{definition}[Independence]
	Two events $A, B \in \mathfrak{F}$ are \textbf{independent} if
	\[
		P[A \cap B] = P[A]\cdot P[B]
	\]
	
	More generally, any collection of events $A_i$, $i = 1,2,\ldots$, is called independent if for any $n \in \textbf{N}$ and any choice of indices $i_k$, $k = 1, 2, \ldots$, 
	\[
		P \left( \bigcap_{k=1}^n A_{i_k} \right) = \prod_{k=1}^n P\left( A_{i_k} \right)
	\]
\end{definition}

\begin{definition}[Conditional Expectation]
	Let $X$ and $Y$ be random variables. Then, given that $f_Y(y) > 0$, the \textbf{conditional distribution} of $X$ given $Y=y$ is given by the conditional density
	\[
		f(x|y) = \frac{f(x,y)}{f_Y(y)}
	\]
	
	And the \textbf{conditional expectation} of $X$ given $Y=y$ is
	\[
		\mathbb{E} [X| Y = y] = \int_{-\infty}^\infty x f(x|y) \mathrm{d}x
	\]
\end{definition}

The intuition behind this definition is to build an estimate of the random variable $X$ given the information available in $Y$.

Some important and very useful properties of conditional expectation are listed below.

\begin{theorem}
	Let $X, Y : \Omega \longrightarrow \textbf{R}^n$ be random variables with $\mathbb{E}[|X|] < \infty$ and $\mathbb{E}[|Y|] < \infty$, $\mathfrak{H} \subseteq \mathfrak{F}$ a $\sigma$-algebra, and let $a, b \in \textbf{R}$.
	\begin{enumerate}
		\item $\mathbb{E} [ a X + b Y | \mathfrak{H}] = a \mathbb{E} [X | \mathfrak{H}] + b \mathbb{E} [Y | \mathfrak{H}]$.
		\item $\mathbb{E} [ \mathbb{E} [X | \mathfrak{H}] ] = \mathbb{E} [X]$.
		\item $\mathbb{E} [X | \mathfrak{H}] = X$ if $X$ is $\mathfrak{H}$-measurable.
		\item $\mathbb{E} [X | \mathfrak{H}] = \mathbb{E} [X]$ if $X$ is independent of $\mathfrak{H}$.
		\item $\mathbb{E} [Y \cdot X | \mathfrak{H}] = Y \cdot \mathbb{E} [X | \mathfrak{H}]$ if $Y$ is $\mathfrak{H}$-measurable.
		\item If $\mathfrak{G} \subseteq \mathfrak{H}$ is a $\sigma$-algebra, then \[ \mathbb{E} [X | \mathfrak{G}] = \mathbb{E} [ \mathbb{E} [X | \mathfrak{H}] | \mathfrak{G}] \]
		\item If $\varphi : \textbf{R} \longrightarrow \textbf{R}$ is convex and $\mathbb{E} [ | \varphi (X) | ] < \infty$, then \[ \varphi (\mathbb{E} [X | \mathfrak{H}]) \leq \mathbb{E} [\varphi(X) | \mathfrak{H}] \]
	\end{enumerate}
\end{theorem}

\begin{definition}[Infinitely often]
If $A_1, A_2, \ldots, A_n, \ldots$ are events in the probability space, then the event
\[
	\bigcap_{n=1}^\infty \bigcup_{m=n}^\infty A_m = \{ \omega \in \Omega : \omega \text{ belongs to infinitely many of the } A_n \}
\]
is called \textbf{$A_n$ infinitely often}, or simply `\textbf{$A_n$ i.o.}'.
\end{definition}

The next lemma helps us check if some sequence of events occurs infinitely often.

\begin{lemma}[Borel-Cantelli]
	If $\sum_{n=1}^\infty P(A_n) < \infty$, then
	\[
		P(A_n \text{ i.o.}) = P \left( \bigcap_{n=1}^\infty \bigcup_{m=n}^\infty A_m \right) = 0
	\]
\end{lemma}

% The limit of random variables and a composition of r.v. are r.v.

The most important distribution in this text is the \textbf{normal} (or \textbf{gaussian}) distribution.
 
\begin{definition}[Normal Distribution]
	If random variable $X$ has mean $\mu$, variance $\sigma^2$ and a density function of the form
	\[
		f(x) = \frac{1}{\sqrt{2\pi} \sigma} \exp \left( \frac{-(x-\mu)^2}{2\sigma^2} \right) 
	\]
	then $X$ is said to have a \textbf{normal distribution}, which we denote by $X \sim N(\mu, \sigma^2)$.
\end{definition}

Notice that $X$ can be normalized (i.e. transformed into a distribution of the form $N(0,1)$) by taking $Z = \frac{X-\mu}{\sigma}$.

%If $X \sim N(\mu, \sigma^2)$, then its moment generating function is
%\[
%	m(t) = \mathbb{E}[e^{tX}] = \int_{-\infty}^{\infty} e^{tx}f(x)dx
%\]

\begin{definition}[Lipschitz and H\"older Conditions]
	A function $f$ is said to be \textbf{H\"older continuous} of order $\alpha$, $0 < \alpha \leq 1$, on an interval $[a,b] \subseteq \textbf{R}$ if there exists a constant $K > 0$, such that for all $x,y \in [a,b]$ we have
	\[
		|f(x) - f(y)| \leq K |x-y|^{\alpha}
	\]
	If $\alpha = 1$, then the function $f$ is said to be \textbf{Lipschitz continuous}.
\end{definition}

\subsection{Stochastic Processes}

\begin{definition}[Stochastic Process]
	A \textbf{stochastic process} is a collection of random variables $\{ X(t) \}$ parametrized by time $t \in T$.  
	
	For each point $\omega \in \Omega$, the mapping $t \longrightarrow X_t(\omega)$ is the respective \textbf{sample path}, also called \textbf{realization} or \textbf{trajectory}.
\end{definition}

\begin{definition}[Filtration]
	A filtration $\textbf{F}$ is a collection of $\sigma$-algebras
	\[
		\textbf{F} = \{ \mathfrak{F}_0, \mathfrak{F}_1, \ldots, \mathfrak{F}_t, \ldots, \mathfrak{F}_T \}
	\]
	such that $\mathfrak{F}_t \subseteq \mathfrak{F}_{t+1}$.
\end{definition}

The idea behind this definition is to model the flow of information. As the time $t$ passes, the observer has more information, and does not lose any previous data. Notice that this implies finer partitions of the sample space $\Omega$.

Given a stochastic process $\{ X(t) \}$, let $\mathfrak{F}_t$ be the $\sigma$-algebra generated by the random variables $X_s$, $s = 0, \ldots, t$. Since $\mathfrak{F}_t \subseteq \mathfrak{F}_{t+1}$, these $\sigma$-algebras form a filtration called the \textbf{natural filtration} of the process $\{ X(t) \}$, and contain all available information of the process up to the time $t$.

\begin{definition}[Martingale]
	A stochastic process $\{M_t \}$ on $(\Omega, \mathfrak{F}, P)$ is called a \textbf{martingale} with respect to a filtration $\mathfrak{M}_t$ if 
	\begin{enumerate}
		\item $M_t$ is $\mathfrak{M}_t$-measurable for all $t$.
		\item $\mathbb{E}[|M_t|] < \infty$ for all $t$.
		\item $\mathbb{E}[M_s | \mathfrak{M}_t] = M_t$ for all $s \geq t$.
	\end{enumerate}
\end{definition}

Intuitively, a martingale is a stochastic process in which the future has no tendency to go up or down. In other words, the expected value of any time in the future is equal to the value of the process at the present time.

\begin{theorem}[Doob's martingale inequality]
	If $M_t$ is a martingale such that the mapping $t \longrightarrow M_t(\omega)$ is continuous a.s., then for all $p \geq 1$, $T \geq 0$ and $\lambda > 0$,
	\[
		P \left[ \sup_{0 \leq t \leq T} |M_t| \geq \lambda \right] \leq \frac{1}{\lambda^p} \mathbb{E} [|M_T|^p]
	\]
\end{theorem}

\subsection{Brownian Motion}

In 1828 the Scottish botanist Robert Brown described the irregular motion of pollen grains suspended in fluid, that is now known as the Brownian Motion. To describe this mathematically, we use a stochastic process $B_t(\omega)$, which is the position at time $t$ of the particle $\omega$.

This can also be understood as the model for the cumulative effect of `noise'. And is also called Wiener process, after N. Wiener, who formalized mathematically the Brownian motion.

\begin{definition}[Brownian Motion]
	A Brownian motion $\{ B(t) \}$ is a stochastic process with the following properties:
	\begin{enumerate}
		\item (Independence of increments). $B(t) - B(s)$, for $t > s$, are independent. That means that this difference does not depend on the past.
		\item (Normal increments). $B(t) - B(s)$ has normal distribution with mean $0$ and variance $t - s$. Notice that by taking $s = 0$ we have $B(t) - B(0) \sim N(0,t)$.
		\item (Continuity of paths). $B(t)$, $t \geq 0$, are continuous functions of $t$. 
	\end{enumerate}
\end{definition}

The existence and continuity of Brownian motion is proved using Kolmogorov's extension and continuity theorem \cite{oksendal2013stochastic}.

\begin{theorem}[Quadratic variation]
	If $t \geq s$,
	\[
		\mathbb{E}[(B_t - B_s)^2] = t - s
	\]
	
	More generally (in $\textbf{R}^n$):
	\[
		\mathbb{E}[(B_t - B_s)^2] = n(t - s)
	\]
\end{theorem}


\begin{theorem}
	\[
		\mathbb{E}[f(B_t)] = \frac{1}{\sqrt{2 \pi t}} \int_{\textbf{R}} f(x) e^{-\frac{x^2}{2t}} \mathrm{d}x
	\]
\end{theorem}

\begin{theorem}
	The expected value of odd moments of $B_t$ (other than one) are zero. And the even moments are given by
	\[
		\mathbb{E}[B_t^{2k}] = \frac{(2k)!}{2^k k!} t^k
	\]
\end{theorem}

Last but not least, two important identities, useful for further calculations are:
\[
	B_j (B_{j+1} - B_j) = \frac{1}{2} [B_{j+1}^2 - B_j^2 - (B_{j+1} - B_j)^2]
\]
\[
	B_j^2 (B_{j+1} - B_j) = \frac{1}{3} (B_{j+1}^3 - B_j^3) - B_j(B_{j+1} - B_j)^2 - \frac{1}{3}(B_{j+1} - B_j)^3
\]

\subsection{Lebesgue Integral}

% Define L^p spaces

\begin{definition}
	A \textbf{space $L^p (\Omega, \mathfrak{F}, P)$} is the space of measurable functions in which the $p$-th power of the absolute value is Lebesgue integrable. I.e., functions of the form
	\[
		\| f \|_p := \left( \int_\Omega |f|^p \mathrm{d}\mu \right)^{1/p} < \infty
	\]

	We can also write this as
	\[
		\| X \|_p := \sqrt[p]{\mathbb{E}[|X|^p]} < \infty
	\]
\end{definition}

A sequence of random variable can converge in different ways. The following definitions are given in an increasing order of strength.

\begin{definition}[Convergence in Distribution]
	A sequence of random variables $\{ X_n \}$ \textbf{converges in distribution} to $X$ if their distribution functions $F_{X_n}(x)$ converge to the distribution function $F_X(x)$ at any point of continuity of $F_X$.
	
	In other words, for any bounded function $f : \textbf{R} \longrightarrow \textbf{R}$ we have
	\[
		\lim_{n \to \infty} \mathbb{E}[f(X_n)] = \mathbb{E}[f(X)]
	\]
	I.e.,
	\[
		\lim_{n \to \infty} \int_{\Omega_n} f(X_n) \mathrm{d}P_n = \int_{\Omega} f(X) \mathrm{d}P
	\]
\end{definition}

\begin{definition}[Convergence in Probability]
	A sequence of random variables $\{ X_n \}$ \textbf{converges in probability} to $X$ if for any $\varepsilon > 0$, we have
	\[
		\lim_{n \to \infty} P[|X_n(\omega) - X(\omega)| > \varepsilon] = 0
	\]
\end{definition}

\begin{definition}[Convergence Almost Surely]
	A sequence of random variables $\{ X_n \}$ \textbf{converges almost surely (a.s.)} to $X$ if for any $\omega$ outside a set of probability zero we have that
	\[
		\lim_{n \to \infty} X_n(\omega) = X(\omega)
	\]
	Alternatively, we can write
	\[
		P[X_n(\omega) \to X(\omega)] = 1
	\]
\end{definition}

\begin{definition}[$L^p$-Convergence]
	A sequence of random variables $\{ X_n \}$ \textbf{converges in $L^p$} to $X$ if $\{X_n\} \subseteq L^p$, $p \in [1,\infty)$, and
	\[
		\lim_{n \to \infty} \|X_n - X\|_p = 0
	\]
	I.e., $\mathbb{E} \left[ |X_n|^p \right] < \infty$ and
	\[
		\lim_{n \to \infty} \mathbb{E} \left[ |X_n - X|^p \right] = 0
	\]
\end{definition}

\newpage
\section{Ito Integrals}

% June-September

In this section, we'll present how the Itô Integral is constructed, showing the intuition behind it and the necessary steps for the proof. However, for full proofs, please refer to \cite{oksendal2013stochastic} or \cite{shreve2004stochastic}.

\subsection{Construction}

We are interested in solving differential equations of the form
\[
	\frac{\mathrm{d}X}{\mathrm{d}t} = b(t,X_t) + \sigma(t,X_t)\cdot \text{`noise'}
\]

This noise will be represented by some stochastic process $W_t$. Our goal is to satisfy the following properties:
\begin{itemize}
	\item If $t_1 \neq t_2$, then $W_{t_1}$ and $W_{t_2}$ are independent.
	\item The collection $\{W_t\}$ is stationary, i.e., the joint distribution of any collections of $W_t$ does not depend on $t$.
	\item $\mathbb{E}[W_t] = 0$ for all $t$.
\end{itemize}

However, a process $W_t$ satisfying the first two conditions cannot have continuous paths. So our first goal is to replace $W_t$ with some convenient stochastic process.

Let $0 = t_0 < t_1 < \ldots < t_m = t$ and consider the discrete version
\[
	X_{k+1} - X_k = b(t_k,X_k)\Delta t_k + \sigma(t_k,X_k)W_k \Delta t_k
\]

Now, replace $W_k \Delta t_k = \Delta V_k = V_{k+1} - V_k$, where $V_t$ is a stochastic process. Since we want $V_t$ to have stationary independent increments with mean zero, the only suitable process with continuous paths is the Brownian motion. Hence, we take $V_t = B_t$, thus obtaining
\[
	X_k = X_0 + \sum_{j=0}^{k-1} b(t_j, X_j) \Delta t_j + \sum_{j=0}^{k-1} \sigma(t_j, X_j) \Delta B_j
\]

And taking the limit as $\Delta t_j$ goes to zero, we have
\[
	X_k = X_0 + \int_0^t b(s, X_s) \mathrm{d}s + \int_0^t \sigma(s, X_s) \mathrm{d}B_s
\]

The question now is to understand the second integral, which can be generalized as
\[
	\int_S^T f(t, \omega) \mathrm{d}B_t(\omega)
\]
where $f : [0, \infty] \times \Omega \longrightarrow \textbf{R}$.

The idea is to first study a simple class of functions and then extended it to more general functions by taking the limit of the integral of simple functions.

So assume that $f$ is of the form
\[
	\varphi(t, \omega) = \sum_{j \geq 0} e_j(\omega) \chi_{[j \cdot 2^{-n},(j+1) \cdot 2^{-n})}(t)
\]
where $\chi$ is the characteristic (indicator) function and $n$ is a natural number. Then we can define
\[
	\int_S^T \varphi(t, \omega) \mathrm{d}B_t(\omega) = \sum_{j \geq 0} e_j(\omega) [B_{t_{j+1}} - B_{t_j}](\omega)
\]
where
\begin{equation*}
	t_k = 
    \begin{cases}
      S \text{ if } k \cdot 2^{-n} < S \\
      T \text{ if } k \cdot 2^{-n} > T \\
      k\cdot 2^{-n} \text{ if } S \leq k \cdot 2^{-n} \leq T
    \end{cases}
\end{equation*}

This definition, however, also leads to difficulties, as a consequence of the variations of the paths of $B_t$. 

In order to deal with that difficulty, notice that a given function $f(t, \omega)$ can be approximated by
\[
	\sum_j f(t_j^\ast,\omega) \chi_{[t_j, t_{j+1})}(t)
\]
where $t_j^\ast \in [t_j, t_{j+1}]$.

With that, we can define
\[
	\int_S^T f(t, \omega) \mathrm{d}B_t(\omega) = \lim_{n \to \infty} f(t_j^\ast,\omega) [B_{t_{j+1}} - B_{t_j}](\omega)
\]

If we take $t_j^\ast = t_j$, the left end point, then we obtain the \textbf{Ito integral}, denoted by
\[
	\int_S^T f(t, \omega) \mathrm{d}B_t(\omega)
\]

If, however, we take $t_j^\ast = (t_j + t_{j+1})/2$, the mid point, then we obtain the \textbf{Stratonovich integral}, denoted by
\[
	\int_S^T f(t, \omega) \circ \mathrm{d}B_t(\omega)
\]

One of the advantages of Ito integral is its application in Finance. Intuitively, by taking the leftmost point, one does not have to know the future, like whether a stock goes up or down.

Related to this intuition, and developing the Ito integral, we must restrict ourselves to functions $f$ that only depends on the behaviour of $B_s(\omega)$ up to the time $t_j$. 

\begin{definition}
	Let $B_t(\omega)$ be a Brownian motion. We define $\mathfrak{F}_t$ as the $\sigma$-algebra generated by the random variables $B_s$, where $s \leq t$. I.e., $\mathfrak{F}_t$ is the smallest $\sigma$-algebra containing all sets
	\[
		\{ \omega : B_{t_1}(\omega) \in F_1, \ldots, B_{t_k}(\omega) \} \in F_k
	\]
	where $t_j \leq t$ and $F_j \subseteq \textbf{R}^n$ are Borel sets, $j \leq k = 1, 2, \ldots$.
\end{definition}

The intuition behind this definition is that $\mathfrak{F}_t$ can be thought as the `history of $B_s$ up to the time $t$'. A function $h(\omega)$ is $\mathfrak{F}_t$-measurable if $h$ depends only on the values from $B_0$ up to $B_t$. I.e., it does not depend on the `future'. 

\begin{definition}[$\mathfrak{N}_t$-Adapted]
	Let $\{ \mathfrak{N}_t \}_{t \geq 0}$ be an increasing family of $\sigma$-algebras of subsets of $\Omega$. A process $g(t,\omega) : [0, \infty) \times \Omega \longrightarrow \textbf{R}^n$ is \textbf{$\mathfrak{N}_t$-adapted} if for each $t \geq 0$ the function $\omega \longrightarrow g(t,\omega)$ is $\mathfrak{N}_t$-measurable.
\end{definition}

\begin{example}
	The process $h_1(t, \omega) = B_{t/2}(\omega)$ is $\mathfrak{F}_t$-measurable and, hence, $\mathfrak{F}_t$-adapted. Notice that this process only depends on previous information.
	
	However, the process $h_2(t, \omega) = B_{2t}(\omega)$ is not $\mathfrak{F}_t$-measurable and, hence, it is not $\mathfrak{F}_t$-adapted. That's because the process $h_2$ depends on future information.
\end{example}

%Example. Let $T > 0$, and $\Delta (t) = \max_{t < s < T} \{ X_s \}$ is not adapted to $X_t$.
%
%If $B_t \sim N(0,t)$ and $X_t = \sigma B)t \sim N(0, \sigma^2 t)$ and $\int \sigma \mathrm{d}B_t$.
%
%If $\Delta(t)$ is a process depending only on $t$, then 
%\[
%	X(t) = \int \Delta(t) \mathrm{d}B_t
%\]
%has Normal distribution at all time.

Now we can define the class of functions for which it is possible to compute the Ito integral.

\begin{definition} \label{def:ito-integral}
	Let $\mathfrak{V}(S,T)$ be the class of functions
	\[
		f(t, \omega) : [0, \infty) \times \Omega \longrightarrow \textbf{R}
	\]
	such that
	\begin{enumerate}
		\item The function $(t, \omega) \longrightarrow f(t, \omega)$ is $\mathfrak{B} \times \mathfrak{F}$-measurable, where $\mathfrak{B}$ denotes the Borel $\sigma$-algebra on $[0, \infty)$.
		\item The function $f(t,\omega)$ is $\mathfrak{F}_t$-adapted.
		\item $\mathbb{E} \left[ \int_S^T f(t, \omega)^2 \mathrm{d}t \right] < \infty$.
	\end{enumerate}
\end{definition}

Given functions $f \in \mathfrak{V}$, in order to define the Ito integral
\[
	I[f](\omega) = \int_S^T f(t, \omega)\mathrm{d}B_t(\omega)
\]
we are going to define $I[\varphi]$ for a simple class of functions $\varphi$ and then show how each $f \in \mathfrak{V}$ can be approximated by $\varphi$.

A function $\varphi \in \mathfrak{V}$ is \textbf{elementary} if it has the form
\[
	\varphi(t, \omega) = \sum_j e_j(\omega) \chi_{[t_j, t_{j+1})}(t)
\]
Since $\varphi \in \mathfrak{V}$, each function $e_j$ is $\mathfrak{F}_j$-measurable. And, as we did before, we define
\[
	\int_S^T \varphi (t, \omega) \mathrm{d}B_t(\omega) = \sum_{j \geq 0} e_j(\omega) [B_{j+1} - B_j](\omega)
\]

To further our development of the Ito integral, we need the following result.

\begin{theorem}[Ito isometry]
	If $\varphi(t, \omega)$ is bounded and elementary, then
	\[
		\mathbb{E}\left[\left( \int_S^T \varphi(t,\omega) \mathrm{d}B_t(\omega) \right)^2 \right] = \mathbb{E} \left[\int_S^T \varphi(t,\omega)^2 \mathrm{d}t \right]
	\]
\end{theorem}

Using this isometry, it is possible to extended the previous definition to functions in $\mathfrak{V}$ by the following steps.

\begin{enumerate}
	\item Let $g(\omega) \in \mathfrak{V}$ be bounded and continuous for each $\omega$. Then there exists elementary functions $\varphi_n \in \mathfrak{V}$ such that
	\[
		\mathbb{E} \left[ \int_S^T (g-\varphi_n)^2 \mathrm{d}t \right] \longrightarrow 0
	\]
	as $n \to \infty$.
	\item Let $h \in \mathfrak{V}$ be bounded, then there exists bounded functions $g_n \in \mathfrak{V}$ such that $g_n (\omega)$ are continuous for all $\omega$ and $n$, and
	\[
		\mathbb{E} \left[ \int_S^T (h-g_n)^2 \mathrm{d}t \right] \longrightarrow 0
	\]
	\item Let $f \in \mathfrak{V}$. Then there exists a sequence of functions $\{h_n\} \subseteq \mathfrak{V}$ such that $h_n$ is bounded for each $n$ and 
	\[
		\mathbb{E} \left[ \int_S^T (f-h_n)^2 \mathrm{d}t \right] \longrightarrow 0
	\]
	as $n \to \infty$.
\end{enumerate}

Please note that we started from bounded and continuous functions, generalized into bounded functions and then generalized further into any function in our class $\mathfrak{V}$.

With these steps, we define the Ito integral as follows.

\begin{definition}[The Ito integral]
	Let $f \in \mathfrak{V}(S,T)$, then the \textbf{Ito integral} of $f$, from $S$ to $T$ is
	\[
		\int_S^T f(t, \omega) \mathrm{d}B_t(\omega) = \lim_{n \to \infty} \int_S^T \varphi_n (t, \omega)  \mathrm{d}B_t(\omega)
	\]
	where the limit is in $L^2(P)$ and $\{\varphi_n \}$ is a sequence of elementary functions such that
	\[
		\mathbb{E} \left[ \int_S^T (f(t, \omega) - \varphi_n(t, \omega))^2 \mathrm{d}t \right] \longrightarrow 0
	\] 
	as $n \to \infty$.
\end{definition}

This new definition induces a generalized form of the Ito isometry.

\begin{theorem}[Ito isometry]
	For all $f \in \mathfrak{V}(S,T)$,	
	\[
		\mathbb{E}\left[\left( \int_S^T f(t,\omega) \mathrm{d}B_t(\omega) \right)^2 \right] = \mathbb{E} \left[\int_S^T f(t,\omega)^2 \mathrm{d}t \right]
	\]
\end{theorem}

\begin{corollary}
	If $f(t, \omega) \in \mathfrak{V}(S,T)$ and $f_n(t, \omega) \in \mathfrak{V}(S,T)$ and
	\[
		\mathbb{E}\left[\left( \int_S^T f_n(t,\omega) - f(t, \omega) \right)^2 \mathrm{d}t \right] \longrightarrow 0
		\]
	as $n \to \infty$, then
	\[
		\int_S^T f_n(t, \omega) \mathrm{d}B_t(\omega) \longrightarrow \int_S^T f(t, \omega) \mathrm{d} B)t(\omega)
	\]
	in $L^2(P)$ as $n \to \infty$.
\end{corollary}

\begin{example}
	We wish to compute the integral
	\[
		\int_0^T B(t) \mathrm{d}B(t)
	\]
	
	\textbf{Step 1.} Let
	\[
		X_n(t) = \sum_{i=0}^{n-1} B_n(t_i^n)[B_n(t_{i+1}^n) - B_n(t_i^n)]
	\]
	be a sequence of elementary functions. Notice that $X_n(t)$ converges to $B(t)$ almost surely as $\max_i (t_{i+1}^n - t_i^n) \to 0$ by the continuity of $B(t)$.
	
	\textbf{Step 2.} Now notice that
	\begin{equation*}
		\begin{aligned}
			B_n(t_i)[B_n(t_{i+1}) - B_n(t_i)] &= B_n(t_{i+1}) B_n(t_i) - B_n^2(t_i) + B_n^2(t_{i+1}) - B_n^2(t_{i+1}) \\
			&= \frac{1}{2} [B_n^2(t_{i+1}) - B_n^2(t_i) - (B_n(t_{i+1}) - B_n(t_i))^2 ]
		\end{aligned}
	\end{equation*}
	
	\textbf{Step 3.} With these two results, we can write the original integral as
	\[
		\int_0^T X_n(t) \mathrm{d}B(t) = \frac{1}{2} \sum_{i=0}^{n-1} \left[ B_n^2(t_{i+1}) - B_n^2(t_i) \right] - \frac{1}{2} \sum_{i=0}^{n-1} \left[ B_n(t_{i+1}) - B_n(t_i) \right]^2
	\]
	
	\textbf{Step 4.} Since the first sum is a telescopic sum and the second one converges in probability to $T$ by the quadratic variation of Brownian motion, we have
	\[
		\int_0^T X_n(t) \mathrm{d}B(t) = \frac{1}{2} B^2(t) - \frac{1}{2} B^2(0) - \frac{1}{2}T = \frac{1}{2} B^2(t) - \frac{1}{2}T 
	\]
	
	Hence, the integral converges in $L^2(P)$ to
	\[
		\int_0^T B(t) \mathrm{d}B(t) = \lim_{n \to \infty} \int_0^T X_n(t) \mathrm{d}B(t) = \frac{1}{2} B^2(t) - \frac{1}{2}T 
	\]
\end{example}

\subsection{Properties} % Shreve p. 148

Before heading to more theoretical and important results, let us notice some natural facts of the Itô integral.

\begin{theorem}
	Let $f, g \in \mathfrak{V}(0,T)$ and let $0 \leq S < U < T$. Then
	\begin{enumerate}
		\item $\int_S^T f \mathrm{d}B_t = \int_S^U f \mathrm{d}B_t + \int_U^T f \mathrm{d}B_t$ for a.a. $\omega$.
		\item $\int_S^T (cf + g) \mathrm{d}B_t = c \int_S^T f \mathrm{d}B_t + \int_S^T g \mathrm{d}B_t$ where $c \in \textbf{R}$.
		\item $\mathbb{E} \left[ \int_S^T f \mathrm{d}B_t \right] = 0$.
		\item $\int_S^T f \mathrm{d}B_t$ is $\mathfrak{F}_T$-measurable.
	\end{enumerate}
\end{theorem}

With the Doob's martingale inequality, it can be proved that the Itô integral can be chosen to depend continuously on $t$. A proof of this fact is on the third chapter of \cite{oksendal2013stochastic}.

Now an important result is that the Itô integral is a martingale.

\begin{theorem}
	Let $f(t, \omega) \in \mathfrak{V}(0,T)$ for all $T$. Then
	\[
		M_t(\omega)  \int_0^t f(s,\omega)\mathrm{d}B_s
	\]
	is a martingale w.r.t. $\mathfrak{F}_t$ and for $\lambda, T > 0$
	\[
		P \left[ \sup_{0 \leq t \leq T} |M_t| \geq \lambda \right] \leq \frac{1}{\lambda^2} \mathbb{E} \left[ \int_0^T f(s,\omega)^2 \mathrm{d}s \right]
	\]
\end{theorem}

Summarizing, the Itô integral is continuous, adapted, linear, a martingale, satisfies the Itô isometry and has Quadratic variation.

\subsection{Extensions}

Using the concept of martingales, we can generalize the Itô integral for a larger class of functions than $\mathfrak{V}$.

Considering the Definition \ref{def:ito-integral}, we can relax the condition 2. into
\begin{itemize}
	\item[2.'] There exists an increasing familiy of $\sigma$-algebras $\mathfrak{H}_t$ such that $B_t$ is a martingale w.r.t. $\mathfrak{H}_t$ and $f_t$ is $\mathfrak{H}_t$-adapted.
\end{itemize}

The idea here is that $B_t$ must remain a martingale with respect to the history of $f_s$. 

Another way of extending the Itô integral definition is by weaking the condition 3. into
\begin{itemize}
	\item[3.'] $P \left[ \int_S^T f(s, \omega)^2 \mathrm{d}s < \infty \right] = 1$
\end{itemize}

Too understand why this works, let $\mathfrak{W}_{\mathfrak{H}} (S,T)$ denote the class of processes satisfying conditions 1, 2' and 3' above. Then, in the 1-dimensional Brownian motion, for all $t$ there exists step functions $f_n \in \mathfrak{W}_{\mathfrak{H}}$ such that
\[
	\int_0^t |f_n - f|^2 \mathrm{d}s \longrightarrow 0
\]
in probability.

Now, since $\int_0^t f_n(s, \omega) \mathrm{d}B_s(\omega)$ converges in probability to a random variable and the limit depends only on $f$, we define
\[
	\int_0^t f(s, \omega) \mathrm{d}B_s(\omega) = \lim_{n \to \infty} \int_0^t f_n(s, \omega) \mathrm{d}B_s(\omega)
\]
where the limit is in probability and $f \in \mathfrak{W}_{\mathfrak{H}}$.

\subsection{Stratonovich integral}

As we saw, the Itô integral is one possible interpretation of the integral 
\[
	\int_S^T f(t, \omega) \mathrm{d}B_t(\omega)
\]

The Stratonovich integral is another possibility and, in general, leads to different results (except when the integrating function has a derivative). In some cases, the Stratonovich definition may be adequate.

In other cases, Itô's feature of `not looking in the future' (as \cite{oksendal2013stochastic} puts it), justifies its use in biology and finance, for example. Moreover, Itô integral is a martingale, and Stratonovich's is not. This gives an important computational advantage to Itô's definition. 

And, to quote \cite{shreve2004stochastic},

\begin{quotation}
	However, it [Stratonovich's integral] is inappropriate for finance. In finance, the integrand represents a position in an asset and the integrator represents the price of that asset. We cannot decide at 1:00 p.m. which position we took at 9:00 a.m. We must decide the position at the beginning of each time interval, and the Ito integral is the limit of the gain achieved by that kind of trading as the time between trades approaches zero.
\end{quotation}

% DRAFTS

%\begin{theorem}
%	If $g(t, B_t)$ is adapted to $B_t$, then
%	\[
%		\int g(t,B_t) \mathrm{d}B_t
%	\]
%	is a martingale as long as $g$ is `reasonable'.
%\end{theorem}
%
%If a SDE has a drift term, then it is not a martingale. If it doesn't, then it is a martingale.

%Differential form of the quadratic variation:
%	\[
%		(\mathrm{d}B_t)^2 = \mathrm{d}t
%	\]
%	
%Simple Ito's Lemma: $\mathrm{d} f = f'(B_t)dB_t + 1/2 f''(B_t)\mathrm{d}t$
%
%Ito's Lemma: if $f$ is smooth function, $X_t : \mathrm{d}X_t = \mu \mathrm{d}t + \sigma \mathrm{d}B_t$, then
%\[
%	\mathrm{d} f(t, X_t) = \left( \frac{\partial f}{\partial t} + \mu \frac{\partial f}{\partial x} + \frac{1}{2} \sigma^2 \frac{\partial^2 f}{\partial x^2} \right) \mathrm{d}t + \sigma \frac{\partial f}{\partial x} \mathrm{d}B_t
%\]
%
%Proof: take Taylor expansion.
%
%Example:
%
%If $f(X) = X^2$, then 
%\[
%	\mathrm{d}f(B_t) = 2 B_t \mathrm{d} B_t + \frac{1}{2} 2 \mathrm{d}t
%\]
%because $\frac{\partial f}{\partial t} = 0$, $\frac{\partial f}{\partial x} = 2x$, $\frac{\partial^2 f}{\partial x^2} = 2$, $\mu = 0$, and $\sigma = 1$.
%
%Another way:
%\[
%	\mathrm{d}f(B_t) = \frac{\partial f}{\partial t} \mathrm{d}t + \frac{\partial f}{\partial x} \mathrm{d}B_t + \frac{1}{2} \frac{\partial^2 f}{\partial x^2} (\mathrm{d}B_t)^2 = 2 B_t \mathrm{d} B_t + \mathrm{d} t
%\]
%
%Example:
%
%If $f(t,X) = e^{\mu t + \sigma X}$, then
%\begin{equation*}
%\begin{aligned}
%	\mathrm{d}f(t, B_t) &= \frac{\partial f}{\partial t} \mathrm{d}t + \frac{\partial f}{\partial x} \mathrm{d}B_t + \frac{1}{2} \frac{\partial^2 f}{\partial x^2} (\mathrm{d}B_t)^2 \\
%	&= \mu e^{\mu t + \sigma x}\mathrm{d}t + \sigma e^{\mu t + \sigma x} \mathrm{d}B_t + \frac{1}{2} \sigma^2 e^{\mu t + \sigma x} \mathrm{d}t \\
%	&= \left( \mu + \frac{1}{2} \sigma^2 \right) f \mathrm{d}t + \sigma f \mathrm{d}B_t
%\end{aligned}
%\end{equation*}
%
%Integral Definition:
%\[
%	F(t, B_t) = \int f(t, B_t) \mathrm{d}B_t + \int g(t, B_t) \mathrm{d}t
%\]
%if
%\[
%	\mathrm{d}F = f \mathrm{d}B_t + g \mathrm{d}t
%\]

\newpage
\section{The Ito Formula and the Martingale Representation Theorem} % Shreve 157 (p.137)

% October-January

\newpage
\section{Stochastic Differential Equations}

% February-May
 
\newpage
\nocite{*}
\bibliographystyle{alpha}
\bibliography{SDE_Notes.bib}
\addcontentsline{toc}{section}{References}

\end{document}